\documentclass[11pt]{article}
\usepackage[letterpaper,margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb,latexsym}
\usepackage{alltt,enumerate,bbm,eucal,graphicx,color,mathpazo,stmaryrd,bussproofs,mathpartir}
\usepackage{tikz,pgfmath,algorithm,algorithmic}
\usepgflibrary{shapes}
\usetikzlibrary{arrows,automata,backgrounds}

\usepackage[style=alphabetic]{biblatex}
\addbibresource{bibtex.bib}

\begin{document}

%% Macros %%
\newcommand\one{\textsf 1}
\newcommand\zero{\textsf 0}
\newcommand\cost{\mathcal C}
\newcommand\Lstar{$L^*$}

%%\newtheorem{remark}{Remark}
%%\newtheorem{question}{Q}
\theoremstyle{remark}
\newtheorem{alg}{Algorithm}

\newtheorem{theorem}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}

\setlength\parindent{0in}
\addtolength\parskip{1ex}
\setlength\fboxrule{.5mm}\setlength{\fboxsep}{1.2mm}
\newlength\courseheader
\setlength\courseheader\textwidth
\addtolength\courseheader{-4mm}
\parindent=0pt
\parskip=1ex

\begin{center}
\framebox{\parbox\courseheader{\large
CS6820 Algorithms\hfill December 15, 2021\\
Final Project \hfill G\"oktu\u{g} Saatcioglu (gs724) \hfill Mark Moeller (mdm367)}}
\end{center}
\medskip

These notes explore the problem of sampling random spanning trees on graphs. The
focus will be to present and analyze Wilson's famous algorithm for this problem,
but we take some detours along the way.

\section{Introduction: Spanning Trees}

In this section we introduce notation and explore basics of distributions on
spanning trees.

\subsection{Definitions}

\begin{defn}
For a connected undirected graph $G = (V, E)$, a collection of edges $T \subseteq E$
form a \emph{spanning tree} if $(V, T)$ is connected and acyclic.
\end{defn}

Suppose the edges have nonnegative costs given by a function $w\colon E \to
\mathbb{R^+}$, then the weight of a spanning tree is:
\[ w(T) = \sum_{e\in T} w(e) \]

\begin{defn}
A spanning tree for $G$ is called the \emph{minimum spanning tree} if it has the
minimum weight of all spanning trees of $G$.
\end{defn}

Prim's and Kruskal's algorithms are classic fast algorithms for finding minimum
spanning trees. Kozen gives an enlightening general framework that includes both
algorithms \cite{kozen}.

In some situations in distributed systems or networking, however, we may not
want the minimum spanning tree necessarily, but instead we want to sample
randomly from a distribution of spanning trees. We will present an algorithm due
to Wilson \cite{wilson} for doing this in Section~\ref{wilson}. Then we will see
how it can be extended to consider graphs with weights. In this case, the
probability of sampling a given tree will be proportional to its weight.

% Some stuff about how many trees there are?


\section{Naive First Attempt}

We might be tempted to try to sample random spanning trees by modifying
Kruskal's algorithm. That is:
\begin{itemize}
\item Choose a random order on edges, perhaps based on edge weights
\item Choose edges from the list in order, skipping an edge if it would make a
cycle
\end{itemize}

Unfortunately, we will not achieve the appropriate distributions following this
path. For a counterexample, consider the triangle graph $G = (\{a,b,c\},
\{(a,b),(b,c),(a,c)\})$, with edge weights:
\[w(e) = \begin{cases}
        2 & \text{ for } e = (a,b)\\
        1 & \text{ for } e = (b,c)\\
        1 & \text{ for } e = (a,c)
        \end{cases}\]

We observe that for this graph there are 3 spanning trees,
$T_0 = \{(a,b), (a,c)\}$,
$T_1 = \{(a,b), (b,c)\}$,
$T_2 = \{(a,c), (b,c)\}$, with weights:

\[w(T) = \begin{cases}
        3 & \text{ for } T = T_0\\
        3 & \text{ for } T = T_1\\
        2 & \text{ for } T = T_2
        \end{cases}\]

Therefore we want to sample $T_0$ or $T_1$ each with probability 3/8, and $T_2$
with probability 1/4. But if we sample the trees by the method described above
(i.e., choosing edges propropotional to their weight---and for this graph just
pick the first two), then we get the following distribution:

\[
(a,b), (a,c)\text{ with Pr }= 1/2 \cdot 1/2 = 1/4, (T_0 \text{selected})\\
(a,c), (a,b)\text{ with Pr }= 1/4 \cdot 2/3 = 1/6, (T_0 \text{selected})\\
(a,b), (b,c)\text{ with Pr }= 1/2 \cdot 1/2 = 1/4, (T_1 \text{selected})\\
(b,c), (a,b)\text{ with Pr }= 1/4 \cdot 2/3 = 1/6, (T_1 \text{selected})\\
(b,c), (a,c)\text{ with Pr }= 1/4 \cdot 1/3 = 1/12, (T_2 \text{selected})\\
(a,c), (b,c)\text{ with Pr }= 1/4 \cdot 1/3 = 1/12, (T_2 \text{selected})
\]

So we get:
\[ \text{Pr}(T_0) = 1/4 + 1/6 = 10/24\\
   \text{Pr}(T_1) = 1/4 + 1/6 = 10/24\\
   \text{Pr}(T_2) = 1/12 + 1/12 = 1/6\]

which is the wrong distribution. We will see in the next section that
\emph{loop-erased random walks} are the key to sampling spanning trees.

\section{Loop-erased Random Walks}

% Talk about unweighted case here?


\section{Wilson's Algorithm}\label{wilson}
% Wilson pseudocode
\subsection{Spanning tree with specified root node}
\begin{algorithm}
\caption{Wilson's algorithm for given root}
\label{alg:root}
\textbf{Input: }Graph $G=(V,E)$, Root $r \in V$ \\
\textbf{Output: }Spanning tree $T$ \\
\begin{algorithmic}[1]
\STATE bool[n] inTree = \{false\} // n-length array, initally all false
\STATE int[n] next = \{-1\}       // n-length array, initally all -1 (null)
\FOR{$i$ in 0 to $n-1$:}
\STATE $u \leftarrow i$
\WHILE{not inTree[u]:}
\STATE next[u] $\leftarrow$ samplesucc(u)
\STATE u $leftarrow$
\ENDWHILE
\STATE $u \leftarrow i$
\WHILE{not inTree[u]:} \label{while}
\STATE inTree[u] $\leftarrow$ true
\STATE $u \leftarrow $next[u]
\ENDWHILE \label{endwhile}
\ENDFOR
\end{algorithmic}
\end{algorithm}

First of all we note that this algorithm is simpler than one might expect! The
loop on lines~\ref{while}-\ref{endwhile} does the loop erasure in a subtle way.
Essentially, we observe that erasing a cycle is \emph{not} a special case, in
the sense that if we end up back where we started, the successor we write down
will overwrite the one that was previously there.
\subsection{Spanning tree with unspecified root}
\begin{algorithm}
\caption{Wilson's algorithm for given root}
\label{alg:root}
\textbf{Input: }Graph $G=(V,E)$ \\
\textbf{Output: }Spanning tree $T$ \\
\begin{algorithmic}
\STATE bool[n] inTree = \{false\} // n-length array, initally all false \\
\STATE int[n] next = \{-1\}       // n-length array, initally all -1 (null) \\
\STATE work in progress...
\end{algorithmic}
\end{algorithm}

\section{Analysis of Wilson's Algorithm}

% Talk about markov chain proof

\section{Implementation}

\printbibliography
\end{document}
